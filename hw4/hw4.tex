\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{bm} 
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\newcommand{\R}{\mathbb{R}}
\geometry{a4paper, margin=1in}

\title{MSBD 5007 HW4}
\author{RONG Shuo}
\date{\today}

\begin{document}

\maketitle

\section*{Question1}
Consider the function \(f: \R^d \to \R\) defined by 
\begin{align*}
    f(\bm{x}) = \sum_{i = 1}^{d}\max(0,1 - x_i),
\end{align*}
where \(x = [x_1, x_2, \cdots, x_n]^T\). Recall that the proximity operator of a function \(g: \R^d \to \R\) is defined as 
\begin{align*}
    \text{prox}_g = \text{arg} \min_{x \in \R^d} \left\{ g(\bm{x}) + \frac{1}{2} \|\bm{x} - \bm{y}\|_2^2\right\}, \bm{y} \in \R^d.
\end{align*}
Derive a closed-form expression for \(\text{prox}_f(\bm{y})\).

\section*{Answer}
Obviously, we can get the \(\text{prox}_f(\bm{y})\) as.
\begin{align*}
    \text{prox}_f(\bm{y}) = \text{arg min}_{\bm{x} \in \R^d} \{ \sum_{i=1}^{d} \max(0, 1 - x_i) + \frac{1}{2} \sum_{i=1}^{d}(x_i - y_i)^2 \}
\end{align*}
We can denote \(\text{prox}_f(\bm{y})_i\) as follow:
\begin{align*}
    \text{prox}_f(\bm{y})_i = \text{arg min}_{x \in \R} \{ \max(0, 1 - x) + \frac{1}{2} (x - y_i)^2 \}
\end{align*}
s.t.
\begin{align*}
    \text{prox}_f(\bm{y}) = \sum_{i=1}^{d} \text{prox}_f(\bm{y})_i
\end{align*}


\noindent
Let \(\phi(x) =  \max(0, 1 - x) + \frac{1}{2} (x - y_i)^2  \) \\
if \(x \geq 1\)
\begin{align*}
    \phi(x) = \{\frac{1}{2} (x - y_i)^2 \} \\
\end{align*}
To minimize this, we need:
\begin{align*}
    &x = y_i &\text{if } y_i \geq 1 \\
    &x = 1        &\text{if } y_i < 1 \\
\end{align*}
Therefore, 
\begin{align*}
    &\text{prox}_f(\bm{y})_i = y_i &\text{if } y_i \geq 1 \\
    &\text{prox}_f(\bm{y})_i = 1 &\text{if } y_i < 1 \\
\end{align*}


if \(x \leq 1\)
\begin{align*}
    \phi(x) = \{ 1 - x + \frac{1}{2} (x - y_i)^2 \} \\
\end{align*}

To minimize this, we need:
\begin{align*}
    &x = y_i + 1 &\text{if }y_i < 0 \\
    &x = 1 &\text{if }y_i \geq 0
\end{align*}
Therefore, 
\begin{align*}
    &\text{prox}_f(\bm{y})_i = y_i + 1 &\text{if } y_i < 0 \\
    &\text{prox}_f(\bm{y})_i = 1 &\text{if } y_i \geq 0 \\
\end{align*}

\noindent
Combining these two, we get:
\begin{align*}
    &\text{prox}_f(\bm{y})_i = \min\{y_i + 1, 1\} = y_i + 1 &\text{if } y_i < 0 \\
    &\text{prox}_f(\bm{y})_i = \min\{1, 1\} = 1 &\text{if } 0 \leq y_i < 1 \\ 
    &\text{prox}_f(\bm{y})_i = y_i &\text{if } y_i \geq 1 \\
\end{align*}

\noindent
So, in conclusion, 
\begin{align*}
    \text{prox}_f(\bm{y}) = [\text{prox}_f(\bm{y})_i]_{i=1}^{d}
\end{align*}
where,
\begin{align*}
    &\text{prox}_f(\bm{y})_i = \min\{y_i + 1, 1\} = y_i + 1 &\text{if } y_i < 0 \\
    &\text{prox}_f(\bm{y})_i = \min\{1, 1\} = 1 &\text{if } 0 \leq y_i < 1 \\ 
    &\text{prox}_f(\bm{y})_i = y_i &\text{if } y_i \geq 1 \\
\end{align*}






\section*{Question2}
In this problem, we study two properties of the 2-norm function \(g(\bm{x}) = \|\bm{x}\|_2\) defined on \(\R^n\). \\
Provide detailed derivations to show that: \\
\noindent
(a) The subdifferential of \(g\) is given by
\begin{align*}
    \partial \|\bm{x}\|_2 = \begin{cases}
        \left\{ \frac{\bm{x}}{\|\bm{x}\|_2}\right\} &\text{if } \bm{x} \ne \bm{0}, \\
        \left\{ \bm{u} \in \R^n | \|\bm{u}\|_2 \leq 1\right\} &\text{if } \bm{x} = \bm{0}.
    \end{cases}
\end{align*}

\noindent
(b) For any \(\alpha > 0\), the proximity operator of \(\alpha \|\cdot\|_2\) is
\begin{align*}
    \text{prox}_{\alpha \|\cdot\|_2}(\bm{y}) = \begin{cases}
        \left(1 - \frac{\alpha}{\|\bm{y}\|_2} \right)\bm{y} &\text{if }\|\bm{y}\|_2 \geq \alpha, \\
        \bm{0} &\text{if } \|\bm{y}\|_2 \leq \alpha.
    \end{cases}
\end{align*}

\section*{Answer}
\subsection*{(a)}
If \(\bm{x} \ne \bm{0}\), we have:
\begin{align*}
    \nabla \|\bm{x}\|_2 = \frac{\bm{x}}{\|\bm{x}\|_2}
\end{align*}
Therefore,
\begin{align*}
    \partial \|\bm{x}\|_2 = \left\{ \frac{\bm{x}}{\|\bm{x}\|_2} \right\}, \text{if } \bm{x} \ne \bm{0}.
\end{align*}

If \(\bm{x} = \bm{0}\), we have:
\begin{align*}
    \|\bm{y}\|_2 &\geq \|\bm{0}\|_2 + \bm{v}^T (\bm{y} - \bm{0}) \\
    \|\bm{y}\|_2 &\geq \bm{v}^T \bm{y}
\end{align*}
According to cs inequality, we know:
\begin{align*}
    &\bm{v}^T \bm{y} \leq \|\bm{v}\|_2\|\bm{y}\|_2 \\
    &\bm{v}^T \bm{y} \leq \|\bm{y}\|_2, \text{  if  } \|\bm{v}\|_2 \leq 1
\end{align*}
Therefore, we get:
\begin{align*}
    \partial \|\bm{x}\|_2 = \left\{ \bm{u} \in \R^n | \|\bm{u}\|_2 \leq 1\right\} &\text{  if  } \bm{x} = \bm{0}.
\end{align*}
In conclusion,
\begin{align*}
    \partial \|\bm{x}\|_2 = \begin{cases}
        \left\{ \frac{\bm{x}}{\|\bm{x}\|_2}\right\} &\text{if } \bm{x} \ne \bm{0}, \\
        \left\{ \bm{u} \in \R^n | \|\bm{u}\|_2 \leq 1\right\} &\text{if } \bm{x} = \bm{0}.
    \end{cases}
\end{align*}


\subsection*{(b)}







\section*{Question 3}
In this problem, we consider the elastic net regression model, which is widely used in statistics for regularized linear regression. The optimization problem is given by
\begin{align*}
    \min_{\bm{x}\in\R^n} \frac{1}{2} \|\bm{A}\bm{x} - \bm{b}\|_2^2 + \lambda_1\|\bm{x}\|_1 + \frac{\lambda_2}{2}\|\bm{x}\|_2^2,
\end{align*}
where \(\bm{A} \in \R^{m \times n}, \bm{b} \in \R^m\), and \(\lambda_1, \lambda_2 > 0\) are regularization parameters. Answer the following: \\
(a) For any \(\beta_1, \beta_2 > 0\), find a closed-form expression for proximity operator \(\text{prox}_{\beta_1\|\cdot\|_1 + \frac{\beta_2}{2}\|\cdot\|_2^2}(\bm{y})\). \\
(b) We apply the forward-backward splitting (i.e. proximal gradient) algorithm. In particular, we apply a forward step for \(\frac{1}{2} \|\bm{A}\bm{x} - \bm{b}\|_2^2\) and a backward step for \(\lambda_1\|\bm{x}\|_1 + \frac{\lambda_2}{2}\|\bm{x}\|_2^2\). Write down the iterative update rule for the resulting algorithm.


\section*{Question 4}
Let \(g: \R^n \to \R\) be a convex function. Prove the following properties: \\
(a) For any \(\bm{x}, \bm{y} \in \R^n\) and for any \(\bm{u} \in \partial g(\bm{x})\) and \(\bm{v} \in \partial g(\bm{y})\), show that
\begin{align*}
    \langle \bm{u} - \bm{v}, \bm{x} - \bm{y}\rangle \geq 0.
\end{align*}
\textit{Hint: Use the definition of the subdifferential}

\noindent
(b) Prove that the proximity operator of \(g\) is nonexpansive; that is, for all \(\bm{x}, \bm{y} \in \R^n\),
\begin{align*}
    \|\text{prox}_g (\bm{x}) - \text{prox}_g(\bm{y})\|_2 \leq \|\bm{x} - \bm{y}\|_2
\end{align*}
\textit{Hint: Apply the result from part (a)}

\noindent
(c) Show that a point \(\bm{x}^*\) minimizes \(g\) if and only if
\begin{align*}
    \bm{x}^* = \text{prox}_g(\bm{x}^*)
\end{align*}







\end{document}