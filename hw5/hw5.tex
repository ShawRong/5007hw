\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=2.5cm]{geometry}
\usepackage{bm} 
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\newcommand{\R}{\mathbb{R}}

\title{MSBD5007 Optimization and Matrix Computation\\
Homework 5}
\author{RONG Shuo}

\begin{document}

\maketitle

\begin{enumerate}
\item Find explicit formulas for the projection of $y \in \mathbb{R}^n$ onto the following non-empty, closed, and convex sets $S \subset \mathbb{R}^n$, respectively.
    \begin{enumerate}
    \item The unit $\infty$-norm ball
    \[S = \{x \in \mathbb{R}^n \mid \|x\|_\infty \leq 1\}.\]
    \item The closed halfspace
    \[S = \{x \in \mathbb{R}^n \mid a^T x \leq b\},\]
    where $a \in \mathbb{R}^n$, $a \neq 0$, and $b \in \mathbb{R}$ are given.
    \end{enumerate}

\item Consider the optimization problem in $x = (x_1, x_2, x_3) \in \mathbb{R}^3$:
\[\begin{aligned}
\min_{x\in\mathbb{R}^3} &\frac{1}{2}(x_1^2 + 4x_2^2 + 9x_3^2) - (4x_1 + 2x_2),\\
\text{s.t.} \quad &x_1 + x_2 + x_3 = 3,\\
&x_i \geq 0, \quad i = 1, 2, 3.
\end{aligned}\]
    \begin{enumerate}
    \item Write down the KKT conditions (stationarity, feasibility, complementary slackness).
    \item Solve the KKT system to find the optimal solution $x^*$, the Lagrange multiplier $\lambda^*$ for the equality constraint, and the multipliers $\mu^* = (\mu_1, \mu_2, \mu_3)$ for the inequality constraints.
    \end{enumerate}

\item We wish to compute the projection of $y \in \mathbb{R}^n$ onto the unit $\ell_1$ball, i.e. solve
\[\begin{aligned}
\min_{x\in\mathbb{R}^n} &\frac{1}{2}\|x - y\|_2^2\\
\text{s.t.} \quad &\|x\|_1 \leq 1.
\end{aligned}\]
    \begin{enumerate}
    \item Derive the Lagrange dual problem and show it can be written as
    \[\max_{\lambda\geq 0} d(\lambda), \quad d(\lambda) = \sum_{i=1}^n h_\lambda(y_i) - \lambda,\]
    where $h_\lambda : \mathbb{R} \to \mathbb{R}$ is the so-called Huber's function (which is a smooth function consisting of a quadratic and two linear pieces) defined by
    \[h_\lambda(t) = \begin{cases}
    \frac{1}{2}t^2, & |t| \leq \lambda,\\
    \lambda |t| - \frac{1}{2}\lambda^2, & |t| \geq \lambda.
    \end{cases}\]
    \item Prove that strong duality holds.
    \item Find the optimal dual multiplier $\lambda^*$.
    \item Give an expression of the projection in terms of $\lambda^*$.
    \end{enumerate}
\item Let $S \subseteq \mathbb{R}^n$ be a nonempty, closed, convex set, and let $\|\cdot\|_2$ denote 2-norm. The projection of any point $y \in \mathbb{R}^n$ onto $S$ is defined by
\[\mathcal{P}_S(y) = \arg\min_{x\in S} \|x-y\|_2.\]
Prove that the projection $\mathcal{P}_S : \mathbb{R}^n \to S$ is nonexpansive: for all $x, y \in \mathbb{R}^n$,
\[\|\mathcal{P}_S(x) - \mathcal{P}_S(y)\|_2 \leq \|x-y\|_2.\]
\end{enumerate}

\section{Answer}
\subsection{(1)}
\subsubsection{(a)}
We know the projection:
\begin{align*}
    \mathcal{P}_S(y) = \arg\min_{\bm{x} \in S} \|\bm{x} - \bm{y}\|_2.
\end{align*}
We consider

\[\min_{\bm{x}\in\mathbb{S}} \|\bm{x}-\bm{y}\|_2\]

\noindent
This means:

\[\min_{\bm{x} \in \mathbb{S}} \sum_{i=1}^n (x_i - y_i)^2\]

\noindent
We can solve for each component $x_i$ independently:

\[\min_{x_i \in [-1,1]} (x_i - y_i)^2\]

\noindent
This is just the Euclidean projection of a scalar onto the interval $[-1,1]$, which gives:

\[x_i = \min(\max(y_i, -1), 1)\]

\noindent
and \[\bm{x} = [x_i]_{1}^{n}\]

\subsubsection{(b)}

We know the projection:
\begin{align*}
    \mathcal{P}_S(y) = \arg\min_{\bm{x} \in S} \|\bm{x} - \bm{y}\|_2 
\end{align*}

\begin{align*}
    \mathcal{L}(\bm{x}, \lambda) = \frac{1}{2} \|\bm{x} - \bm{y}\|_2^2 + \lambda (\bm{a}^T \bm{x} - b), \quad \lambda \geq 0
\end{align*}

We know the KKT conditions:
\begin{align*}
    \nabla_x \mathcal{L} &= \bm{x} - \bm{y} + \lambda \bm{a} = 0 \\
    \bm{x}^* &= \bm{y} - \lambda \bm{a}
\end{align*}

and
\begin{align*}
    \bm{a}^T \bm{x}^* \leq b \\
    \bm{a}^T (\bm{y} - \lambda \bm{a}) \leq b \\
    \bm{a}^T \bm{y} - \lambda \|\bm{a}\|^2 \leq b \\
    \lambda \geq \frac{\bm{a}^T\bm{y} -b}{\|\bm{a}\|^2}
\end{align*}

and we know:
\begin{align*}
    \lambda(\bm{a}^T\bm{x} - b) = 0 \\
    \lambda(\bm{a}^T\bm{y} - \lambda\|\bm{a}\|^2 - b) = 0 \\
\end{align*}
So we get \(\lambda = \max(0, \frac{\bm{a}^T\bm{y} - b}{\|\bm{a}\|^2})\)

\noindent
So we can get 
\begin{align*}
    \mathcal{P}_S(\bm{y}) = \bm{y} - \max(0, \frac{\bm{a}^T\bm{y} - b}{\|\bm{a}\|^2})\bm{a}
\end{align*}

\subsection{(2)}
\subsubsection{(a)}
We can write the Lagrangian Function:
\begin{align*}
    \mathcal{L}(x, \lambda, \mu) = \frac{1}{2} (x_1^2 + 4x_2^2 + 9x_3^2) - (4x_1 + 2x_2) - \lambda(x_1 + x_2 + x_3 - 3) - \sum_{i=1}^{3} \mu_i x_i 
\end{align*}

\begin{align*}
    \nabla_{x} \mathcal{L} = 0 \\
    x_1 - 4 - \lambda - \mu_1 = 0 \\
    4x_2 - 2 - \lambda - \mu_2 = 0 \\
    9x_3 - \lambda - \mu_3 = 0 \\
\end{align*}

\begin{align*}
    x_1 + x_2 + x_3 = 3 \\
    x_i \geq 0
\end{align*}

\begin{align*}
    \mu_i \geq 0 \\
    \mu_i x_i = 0
\end{align*}

\subsubsection{(b)}
We need to do analysis of the solution first.

\begin{align*}
    x_1 > 0, x_2 > 0, x_3 > 0 \quad \text{invalid} \\
    x_1 = 0, x_2 > 0, x_3 > 0 \quad \text{invalid} \\
    x_1 > 0, x_2 = 0, x_3 > 0 \quad \text{invalid} \\
    x_1 > 0, x_2 > 0, x_3 = 0 \quad \text{valid} \\
\end{align*}

if \(x_3 = 0\), we know \(\mu_1 = 0, \mu_2 = 0\). Therefore, we get:
\begin{align*}
    x_1 = \lambda + 4 \\
    x_2 = \frac {\lambda + 2} {4} \\
    \mu_3 = -\lambda
\end{align*}
We know \(x_1 + x_2 = 3\).
\begin{align*}
    \lambda + 4 + \frac {\lambda + 2} {4} = 3 \\
    \lambda = -\frac{6}{5}
\end{align*}
s.t.
\begin{align*}
    x_1 = \frac{14}{5} \\
    x_2 = \frac{1}{5} \\
    x_1 = 0 \\
    \mu_3 = \frac{6}{5} \\
\end{align*}

Therefore, we can conclude:
\begin{align*}
    x_1 = \frac{14}{5} \\
    x_2 = \frac{1}{5} \\
    x_1 = 0 \\
    \mu_1 = 0 \\
    \mu_2 = 0 \\
    \mu_3 = \frac{6}{5} \\
    \lambda = -\frac{6}{5}
\end{align*}

\subsection{(3)}
\subsubsection{(a)}


\end{document}